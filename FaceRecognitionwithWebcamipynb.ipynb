{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceRecognitionwithWebcamipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCXygkyyMQ2bmbTCXq9z6N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeynepmerve97/FaceRecognitionWithWebcam/blob/main/FaceRecognitionwithWebcamipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV9tz1M2Bbh2"
      },
      "source": [
        "Face Recognition with Webcam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mea_i1r6_2N6"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import os\n",
        "import pandas as pd\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24vIEORwAWig"
      },
      "source": [
        "First Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWcnT14-ASuw"
      },
      "source": [
        "model_first = Sequential()\n",
        "model_first.add(Conv2D(32, kernel_size = (5,5),padding = 'Same',strides=(2, 2),\n",
        "                 activation ='relu', input_shape = (50,50,3) ))\n",
        "model_first.add(Conv2D(64, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_first.add(MaxPooling2D(5,5,padding='same'))\n",
        "model_first.add(Dropout(0.25))\n",
        "\n",
        "model_first.add(Conv2D(128, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_first.add(Conv2D(256, kernel_size = (5,5),padding = 'Same', \n",
        "                  \n",
        "                 activation ='relu'))\n",
        "\n",
        "model_first.add(Dropout(0.50))\n",
        "\n",
        "model_first.add(Flatten())\n",
        "model_first.add(Dense(128, activation = \"relu\"))\n",
        "model_first.add(Dropout(0.50))\n",
        "\n",
        "model_first.add(Dense(3, activation = \"softmax\"))\n",
        "     \n",
        "    \n",
        "model_first.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAxYTMPTAdZJ"
      },
      "source": [
        "Second Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcIhILUTAaGt"
      },
      "source": [
        "model_second= Sequential()\n",
        "model_second.add(Conv2D(32, kernel_size = (5,5),padding = 'Same',strides=(2, 2),\n",
        "                 activation ='relu', input_shape = (50,50,3) ))\n",
        "model_second.add(Conv2D(64, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_second.add(MaxPooling2D(5,5,padding='same'))\n",
        "model_second.add(Dropout(0.25))\n",
        "\n",
        "model_second.add(Conv2D(128, kernel_size = (5,5),padding = 'Same', \n",
        "                 activation ='relu'))\n",
        "model_second.add(Conv2D(256, kernel_size = (5,5),padding = 'Same', \n",
        "                  \n",
        "                 activation ='relu'))\n",
        "\n",
        "model_second.add(Dropout(0.50))\n",
        "\n",
        "model_second.add(Flatten())\n",
        "model_second.add(Dense(128, activation = \"relu\"))\n",
        "model_second.add(Dropout(0.50))\n",
        "\n",
        "model_second.add(Dense(3, activation = \"sigmoid\"))\n",
        "     \n",
        "    \n",
        "model_second.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['binary_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofoUBlK2AfPz"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-XxOONXAhVN"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  shear_range = 0.2,\n",
        "                                  zoom_range = 0.2,\n",
        "                                  horizontal_flip=True)\n",
        "\n",
        "test_datagen =  ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsD2-kAYAjIC"
      },
      "source": [
        "train_set = train_datagen.flow_from_directory('dataset/train',\n",
        "                                             target_size =(50,50),\n",
        "                                             batch_size=32,\n",
        "                                             class_mode='categorical')\n",
        "\n",
        "test_set = train_datagen.flow_from_directory('dataset/test',\n",
        "                                             target_size =(50,50),\n",
        "                                             batch_size=32,\n",
        "                                             class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt9bcKDPAnJM"
      },
      "source": [
        "#steps_per_epoch = len(X_train)\n",
        "#validation_steps = len(X_test)//batch_size # if you have test data\n",
        "\n",
        "hist1 = model_first.fit_generator(\n",
        "train_set,\n",
        "steps_per_epoch=int(8000/3750),\n",
        "epochs=15,\n",
        "validation_data = test_set,\n",
        "validation_steps =int(500/3750))\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMtjFCdwApgw"
      },
      "source": [
        "score_first = model_first.evaluate(test_set, verbose=0)\n",
        "print('model Test accuracy: {0:%}'.format(score_first[1]))\n",
        "print('model Test LOSS: {0:%}'.format(score_first[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GQTqRN1AqB5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist1.history['accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('fist_model_accuracy.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsQNwHneAr8B"
      },
      "source": [
        "plt.plot(hist1.history['loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "plt.savefig('first_model_loss.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrTw9tNZA4T3"
      },
      "source": [
        "Secon Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j17Kx7Y_A0KJ"
      },
      "source": [
        "hist2_2 = model_second.fit_generator(\n",
        "train_set,\n",
        "steps_per_epoch=int(8000/3750),\n",
        "epochs=15,\n",
        "validation_data = test_set,\n",
        "validation_steps =int(400/3750))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyYNNlKMA9OZ"
      },
      "source": [
        "score_second = model_second.evaluate(test_set, verbose=0)\n",
        "print('model Test accuracy: {0:%}'.format(score_second[1]))\n",
        "print('model Test LOSS: {0:%}'.format(score_second[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKrNE9DLBAXp"
      },
      "source": [
        "Face Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIPenuetBB9R"
      },
      "source": [
        "train_set.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9Kb1ps_BExr"
      },
      "source": [
        "##xml dosyasını kullanılabilir hale getiriliyor.\n",
        "face_cascade= cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "classes = ['merve','nehir','sevim']\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp9X9j2aBHT7"
      },
      "source": [
        "#kamera açılıyor\n",
        "cap = cv2.VideoCapture(0)\n",
        "while True:\n",
        "    _,frame = cap.read()\n",
        "    # görüntüde yüz bulmak için detectMultiScale fonksiyonunu kullanıyoruz.\n",
        "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
        "    \n",
        "    # her yüz için tespit yapıyor\n",
        "    for (x,y,w,h) in faces:\n",
        "        #yüzün çevresine çerçeve yerleştiriyoruz.\n",
        "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)\n",
        "        face = frame[y:y+h, x:x+w]\n",
        "        \n",
        "        if type(face) is np.ndarray:\n",
        "            face = cv2.resize(face, (50,50))\n",
        "            #girdi olarak dizi nesnesini alır ve dizi nesnesinden oluşturulan görüntü nesnesini döndürür.\n",
        "\n",
        "            im = Image.fromarray(face, 'RGB')\n",
        "            img_array= np.array(im)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "            pred = model_second.predict(img_array)\n",
        "            label = classes[pred.argmax()]\n",
        "            \n",
        "    cv2.putText(frame, str(label), (x,y), cv2.FONT_HERSHEY_SIMPLEX, .7,(0,255,0),2)\n",
        "    cv2.imshow('frame', frame)\n",
        "    k = cv2.waitKey(100) & 0xff # esc tuşuna basarak çıkış yapılır.\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()   \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}